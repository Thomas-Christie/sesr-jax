The evolution of the project was as follows:

1. Literature review - We were initially keen to explore Neural Architecture Search, but decided that the compute required to make an interesting project would be very large, making this project too risky. Instead, we decided to take a paper from the [MLSys 2022 conference](https://mlsys.org/Conferences/2022/Dates) which looked at performing super-resolution in an efficient manner using collapsing blocks. The paper was [Collapsible Linear Blocks for Super-Efficient Single Image Super Resolution](https://arxiv.org/pdf/2103.09404v4.pdf). Given the recency of the paper, we thought there would be value in re-implementing the model from scratch to aid in reproducibility, with the option to explore some techniques learned on the L46 course, such as pruning.
2. Initial Model Implementation - We implemented the model in JAX, as the original model was written in TensorFlow. Our implementation involved two models; one with the expanded weights and one with collapsed weights. After some initial debugging we got the model working, but found that the output of the collapsed model was different compared to that of the expanded model.
3. Fixing the Model - We then compared our implementation to that of the authors, and wrote an implementation more like theirs (found on branch `new-sesr`), which had tighter coupling between the expanded and collapsed models. Whilst doing this, we found that there was an issue in their code, which we also had in our original code, which meant that bias terms in collapsible layers weren't handled correctly. This is also an open issue on their GitHub repository: [https://github.com/ARM-software/sesr/issues/14](https://github.com/ARM-software/sesr/issues/14).
4. Updating the Collapsing Algorithm - Given this flaw in their collapsing algorithm, we then went back to our original implementation (which is on the `master` branch), and updated the collapsing algorithm so that it handles bias terms correctly. Having done this, we trained an M3 model, which reached a PSNR score of 34.915 after 300 epochs (the authors reported a score of 35.03), which we were pleased with.
5. Producing Upscaled Images in RGB Colour Space - We then decided to inspect the upsampled images produced by the model in RGB space for a qualitative analysis. The model used images in the YCbCr colour space, and only performed upsampling on the Y channel. We found that this was common in the super-resolution literature, and that it was common to use a classic algorithm such as bicubic interpolation for upsampling the Cb and Cr channels, so did this and converted back to RGB for a qualitative analysis.
6. Pruning - We then decided to extend the model by performing pruning. More specifically, we used a form of pruning known as iterative magnitude pruning introduced in a fairly recent paper, [The Lottery Ticket Hypothesis](https://arxiv.org/pdf/1803.03635.pdf). By rewinding unpruned weights to their initial values (or values from a few epochs into training) in between pruning iterations, this paper saw improved accuracy of models on image classification tasks, with the resulting pruned models requiring less epochs to train. This achieved surprisingly good results on our M3 model, enabling it to reach similar PSNR values (~34.9) with less than 1/3 the number of epochs required to train the original M3 model.  